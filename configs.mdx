### WandB Config

```python
train_engine.wandbConfig:
    wandb_api_key:str
    project:str
    config:dict
```

`wandb_api_key:str` Your unique API key for authenticating with the Weights and Biases (wandb) platform.

`project:str` The name of the wandb project where your experiment will be logged.

`config:dict` A dictionary containing configuration parameters for your experiment, such as hyperparameters, settings, or any other key-value pairs relevant to your run.

### Prompt Config

```python
train_engine.PromptConfig:
    new_padding_token: Optional[str] = None
    use_chat_template: Optional[bool] = False
    system_message_key: Optional[str] = None
    system_message: Optional[str] = None
    clm_column: Optional[str] = None
    context_length: Optional[int] = 1024
```

`new_padding_token`: A new padding token that will be added to the tokenizer (e.g. <PAD>). Note that this might need some fine-tuning or it might cause unexpected behaviour.

`use_chat_template`: If a chat tempalte will be used. This is usefull to include a system message, a user message and have the response after response tempalte (in supervised fine tuning) to be the assistant's response.

`system_message_key`: The key in the dataset that indicates which key should be used as a system message. Useful in SFT.

`system_message`: The string that would be used as the system message. Note: provide either system_message or system_message_key.

`clm_column`: Causal Language Modelling (CLM) column. This is the column from which the text to train for CLM will be extracted. 

`context_length`: For CLM, the context length for the pre-processing of text. 

### SFT Prompt Config

```python
train_engine.sftPromptConfig(PromptConfig):
    keys: List[str] = field(default_factory=list)
    template: str = ""
    response_template: str = ""
```

`keys`: the keys from the dataset that would be used to populate the SFT template.

`template`: the prompt template used for SFT (e.g. `"### QUESTION {question}, ###ANSWER: {answer}"`). This will be formated by the keys provided. 

`response_template`: The tempalte used to train the LLM for SFT. (e.g. `###ANSWER`).

### Inference time genreation config

```python
inference_tools.GenerationConfig:
    train_type:str
    max_length:int
    num_return_sequences:int
    do_sample:bool
    top_k:int
    top_p:float
    temperature:float
    prompt_template:str
    response_template:str
    keys:list
```
`train_type`: currently only accepted formats are `sft` or `clm`. 

`max_length`: maximum length of the generated sequence with the model.

`num_return_sequences`: number of sequences generated.

`do_sample`: weather to sample from the output logits or no. 

`top_k`: top k tokens based on the probability.

`top_p`: this would define the top tokens that are above the certai probability. 

`tempreture`: this defines the "randomness" in the sampling process.

`prompt_template`: the template used for a SFT training process. This is set in the 'sftPromptConfig`. 

`response_template`: This is the response template used in SFT training, set in the `sftPromptConfig`. 

`keys`: keys used during the SFT training process, used in `sftPromptConfig`. 
